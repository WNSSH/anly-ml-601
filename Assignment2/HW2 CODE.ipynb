{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import random\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm\n",
    "import math\n",
    "\n",
    "\n",
    "data=pd.read_csv('kernel_regression_1.csv')\n",
    "x_ = np.linspace(-5,5,200)\n",
    "\n",
    "size=len(data)\n",
    "X=data.x.values\n",
    "Y=data.y.values\n",
    "k1 = lambda x,xp: math.exp(-3*abs(x-xp))\n",
    "k2 = lambda x,xp: math.exp(-2*math.sqrt((x-xp)**2))\n",
    "k3 = lambda x,xp: abs(x-xp)<0.5\n",
    "kernel1 = lambda x: sum(k1(x,X[i])*Y[i] for i in range(size))/sum(k1(x,X[i]) for i in range(size))\n",
    "kernel2 = lambda x: sum(k2(x,X[i])*Y[i] for i in range(size))/sum(k2(x,X[i]) for i in range(size))\n",
    "kernel3= lambda x: sum(k3(x,X[i])*Y[i] for i in range(size))/sum(k3(x,X[i]) for i in range(size))\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.scatter(data.x,data.y,color='pink',label='Raw Data')\n",
    "plt.plot(x_,[kernel1(x) for x in x_],'red',label = 'Exponential Kernel')\n",
    "plt.plot(x_,[kernel2(x) for x in x_],'yellow',label = 'Radial Basis Kernel')\n",
    "plt.plot(x_,[kernel3(x) for x in x_],'blue',label = 'Uniform Kernel')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Different kernels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('kernel_regression_2.csv')\n",
    "X=data.x.values\n",
    "Y=data.y.values\n",
    "Z=data.z.values\n",
    "size=len(data)\n",
    "\n",
    "k1 = lambda x,y,xp,yp: math.exp(-3*max(abs(x-xp),abs(y-yp)))\n",
    "k2 = lambda x,y,xp,yp: math.exp(-2*math.sqrt((x-xp)**2+(y-yp)**2))\n",
    "k3 = lambda x,y,xp,yp: max(abs(x-xp),abs(y-yp))<0.5\n",
    "\n",
    "mhx1 = lambda x,y: sum(k1(x,y,X[i],Y[i])*Z[i] for i in range(size))/sum(k1(x,y,X[i],Y[i]) for i in range(size))\n",
    "mhx2 = lambda x,y: sum(k2(x,y,X[i],Y[i])*Z[i] for i in range(size))/sum(k2(x,y,X[i],Y[i]) for i in range(size))\n",
    "mhx3 = lambda x,y: sum(k3(x,y,X[i],Y[i])*Z[i] for i in range(size))/sum(k3(x,y,X[i],Y[i]) for i in range(size))\n",
    "\n",
    "x_ = list(np.random.random(100)*5)+list(np.random.random(100)*(-5))\n",
    "y_ = list(np.random.random(100)*5)+list(np.random.random(100)*(-5))\n",
    "plt.figure(figsize=(15,8))\n",
    "ax = plt.subplot(111,projection='3d')\n",
    "ax.scatter(X,Y,Z,c='pink',label='RawData')\n",
    "ax.plot_trisurf(x_,y_,[mhx1(x_[i],y_[i]) for i in range(200)],linewidth=0.1,label='Exponential Kernel')\n",
    "plt.title('Exponential Kernel')\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "ax = plt.subplot(111,projection='3d')\n",
    "ax.scatter(X,Y,Z,c='brown',label='RawData')\n",
    "ax.plot_trisurf(x_,y_,[mhx2(x_[i],y_[i]) for i in range(200)],linewidth=0.1,label='Radial basis')\n",
    "plt.title('Radial Basis Kernel')\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "ax = plt.subplot(111,projection='3d')\n",
    "ax.scatter(X,Y,Z,c='green',label='RawData')\n",
    "ax.plot_trisurf(x_,y_,[mhx3(x_[i],y_[i]) for i in range(200)],linewidth=0.1,label='Uniform')\n",
    "plt.title('Uniform Kernel')\n",
    "\n",
    "\n",
    "for bandwith in range(3,9):\n",
    "    k2 = lambda x,y,xp,yp: math.exp(-2*math.sqrt(((x-xp)/bandwith)**2+((y-yp)/bandwith)**2))\n",
    "    mhx2 = lambda x,y: sum(k2(x,y,X[i],Y[i])*Z[i] for i in range(size))/sum(k2(x,y,X[i],Y[i]) for i in range(size))\n",
    "    plt.figure(figsize=(20,8))\n",
    "    ax = plt.subplot(111,projection='3d')\n",
    "    ax.scatter(X,Y,Z,c='black',label='RawData')\n",
    "    ax.plot_trisurf(x_,y_,[mhx2(x_[i],y_[i]) for i in range(200)],linewidth=0.1,label='Radial basis')\n",
    "    plt.title('Radial Basis Kernel with bandwith ' +str(bandwith))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('svm.csv')\n",
    "X=data[['x','intercept']].values\n",
    "Y=data['y'].values\n",
    "label=data['class'].values\n",
    "\n",
    "def compute_cost(W, X, Y):\n",
    "    N = X.shape[0]\n",
    "    distances = 1 - Y * (np.dot(X, W))\n",
    "    distances[distances > 0] = 1\n",
    "    hinge_loss = (np.sum(distances) / N)\n",
    "    return abs(hinge_loss)\n",
    "\n",
    "def calculate_gradient(W,X,Y,ratio):\n",
    "    idx=random.sample(range(0, len(X)),int(len(X)*ratio))\n",
    "    dw=np.zeros(len(W))\n",
    "    for i in idx :\n",
    "        if (Y[i]*np.dot(X[i], W)) < 1:\n",
    "            di= (W-2*X[i] * Y[i])\n",
    "        else:\n",
    "            di=W\n",
    "        dw+=di\n",
    "    return dw/int(len(X)*ratio)\n",
    "def eta(i):\n",
    "    return 1.0/(i*2)\n",
    "def svm_train(X,Y,ratio):\n",
    "    max_epoch=201\n",
    "    w=np.array([-800,0])\n",
    "    res=[]\n",
    "    for epoch in range(1,max_epoch):\n",
    "        w=w-eta(epoch)*calculate_gradient(w,X,Y,ratio)\n",
    "        loss=compute_cost(w, X, Y)\n",
    "        res.append([epoch,w,loss])\n",
    "    return w,res\n",
    "\n",
    "w,res=svm_train(X,Y,0.7)\n",
    "w\n",
    "\n",
    "import time\n",
    "run_time=[]\n",
    "for i in np.linspace(0.1,1.0,45):\n",
    "    start = time.time()\n",
    "    _,_=svm_train(X,Y,i)\n",
    "    stop = time.time()\n",
    "    run_time.append([int(i*len(X)), stop-start])\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "x_vals = np.linspace(-10,10,1000)\n",
    "y_vals = w[1] + w[0] * x_vals\n",
    "plt.plot(x_vals, y_vals, '--',color='black')\n",
    "plt.scatter(X[:,0],Y,c=label)\n",
    "plt.title('Decsison Boundary')\n",
    "plt.show()\n",
    "\n",
    "res=np.array(res,object)\n",
    "plt.plot(res[:,0],res[:,2],color='black')\n",
    "plt.title('loss over time')\n",
    "\n",
    "run_time=np.array(run_time)\n",
    "plt.plot(run_time[:,0],run_time[:,1],color='blue')\n",
    "plt.title('Run time for different n')\n",
    "\n",
    "res=np.array(res,object)\n",
    "plt.plot(res[:,0],res[:,2],color='black')\n",
    "plt.title('loss over time')\n",
    "\n",
    "run_time=np.array(run_time)\n",
    "plt.plot(run_time[:,0],run_time[:,1],color='blue')\n",
    "plt.title('Run time for different n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('gibbs.csv')\n",
    "n = len(data)\n",
    "beta = 4\n",
    "alpha = 30\n",
    "lambda_ = np.random.gamma(sum(data.value)+alpha,beta/(n*beta+1),888)\n",
    "\n",
    "def likelihood_func(lambda_):\n",
    "    res=1\n",
    "    for value in data.value:\n",
    "        res*=stats.poisson.pmf(value,lambda_)\n",
    "    return -math.log(res)\n",
    "\n",
    "lambda_.sort()\n",
    "plt.plot(lambda_,[likelihood_func(l) for l in lambda_],color='black')\n",
    "plt.title('Likelihood with different lambda')\n",
    "\n",
    "plt.hist(lambda_,bins = 100,color='black')\n",
    "plt.title('Posterior Distribution')\n",
    "\n",
    "plt.hist(np.random.poisson(np.mean(lambda_),1000),bins=100,color='pink')\n",
    "plt.title('Posterior Predictive Distribution')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm\n",
    "import pymc3 as pm\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "from pymc3.math import switch\n",
    "import matplotlib.pyplot as plt\n",
    "import plotnine as pn\n",
    "from plotnine import *\n",
    "import corner "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "data=pd.read_csv('change_point1.csv')\n",
    "plt.plot(data['x'],data['y'],color='blue')\n",
    "plt.show()\n",
    "\n",
    "count_data.plot(x = 'time', y ='observed_counts',  kind = 'bar', figsize=(15,5))\n",
    "\n",
    "mean_of_counts = count_data.observed_counts.mean()\n",
    "alpha = 1.0/mean_of_counts\n",
    "l = len(count_data)\n",
    "model = pm.Model()\n",
    "\n",
    "with model:\n",
    "\n",
    "    lambda_1 = pm.Exponential('lambda_1',alpha)\n",
    "    lambda_2 = pm.Exponential('lambda_2',alpha)\n",
    "\n",
    "    tau = pm.DiscreteUniform('tau',lower = 0, upper= l-1)\n",
    "    \n",
    "with model:\n",
    "    idx = count_data.time\n",
    "    lambda_ = pm.math.switch(tau > idx, lambda_1, lambda_2) \n",
    "with model:\n",
    "    observation = pm.Poisson(\"obs\", lambda_, observed=count_data.observed_counts)\n",
    "chains = 2\n",
    "samples = 1000\n",
    "\n",
    "with model:\n",
    "    step = pm.Metropolis()\n",
    "    trace = pm.sample(draws = samples, \n",
    "                      chains = chains, \n",
    "                      tune=5000,\n",
    "                      step=step)\n",
    "\n",
    "# - Posterior values -\n",
    "lambda_1_samples =  trace['lambda_1']\n",
    "lambda_2_samples = trace['lambda_2']\n",
    "tau_samples = trace['tau']\n",
    "\n",
    "# - Posterior distribution -\n",
    "posterior_dist = pd.DataFrame({'lambda_1': lambda_1_samples, 'lambda_2': lambda_2_samples, 'tau' : tau_samples})\n",
    "posterior_dist = posterior_dist.unstack().reset_index()\n",
    "posterior_dist = posterior_dist.rename(columns = {'level_0':'Parameter',\n",
    "                                                  'level_1':'Sample',\n",
    "                                                  0:'simulated_parameter'})\n",
    "\n",
    "import math\n",
    "data=pd.read_csv('change_point1.csv')\n",
    "niter = 2000 #number of iterations for the MCMC algorithm\n",
    "t = np.arange(0,len(data)) #array of observation positions ('time')\n",
    "data=data['y'].values\n",
    "\n",
    "with pm.Model() as model:\n",
    "    # define exponential prior\n",
    "    alpha=pm.Exponential('alpha',1/np.mean(data))\n",
    "    beta=pm.Exponential('beta',1/np.mean(data))\n",
    "    tau=pm.DiscreteUniform(\"tau\",t.min(),t.max())\n",
    "    lambda_=T.switch(tau>=t, alpha, beta)\n",
    "    ## note that the factorial constant is ignored\n",
    "    logp = -lambda_ + T.log(lambda_)*data\n",
    "    \n",
    "    def logp_func(data):\n",
    "        return logp.sum()\n",
    "    \n",
    "    L_obs=pm.DensityDist('L_obs',logp_func, observed=data)\n",
    "    #start MCMC algorithm\n",
    "    start = pm.find_MAP()\n",
    "    #iterate MCMC\n",
    "    trace = pm.sample(niter, start=start, random_seed=123, progressbar=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "data=pd.read_csv('radon.csv')\n",
    "\n",
    "from pymc3 import get_data\n",
    "srrs2 = pd.read_csv(get_data('srrs2.dat'))\n",
    "srrs2.columns = srrs2.columns.map(str.strip)\n",
    "srrs_mn = srrs2[srrs2.state=='MN'].copy()\n",
    "srrs_mn['fips'] = srrs_mn.stfips*1000 + srrs_mn.cntyfips\n",
    "cty = pd.read_csv(get_data('cty.dat'))\n",
    "cty_mn = cty[cty.st=='MN'].copy()\n",
    "cty_mn[ 'fips'] = 1000*cty_mn.stfips + cty_mn.ctfips\n",
    "\n",
    "srrs_mn = srrs_mn.merge(cty_mn[['fips', 'Uppm']], on='fips')\n",
    "srrs_mn = srrs_mn.drop_duplicates(subset='idnum')\n",
    "u = np.log(srrs_mn.Uppm)\n",
    "srrs_mn.county = srrs_mn.county.map(str.strip)\n",
    "mn_counties = srrs_mn.county.unique()\n",
    "counties = len(mn_counties)\n",
    "county_lookup = dict(zip(mn_counties, range(len(mn_counties))))\n",
    "\n",
    "county = srrs_mn['county_code'] = srrs_mn.county.replace(county_lookup).values\n",
    "radon = srrs_mn.activity\n",
    "srrs_mn['log_radon'] = log_radon = np.log(radon + 0.1).values\n",
    "floor_measure = srrs_mn.floor.values\n",
    "\n",
    "srrs_mn.activity.apply(lambda x: np.log(x+0.1)).hist(bins=25);\n",
    "\n",
    "from pymc3 import Deterministic\n",
    "from pymc3 import Model, sample, Normal, HalfCauchy, Uniform, model_to_graphviz\n",
    "with Model() as hierarchical_intercept:\n",
    "    # Priors\n",
    "    sigma_a = HalfCauchy('sigma_a', 5)\n",
    "    \n",
    "    # County uranium model for slope\n",
    "    gamma_0 = Normal('gamma_0', mu=0., sigma=1e5)\n",
    "    gamma_1 = Normal('gamma_1', mu=0., sigma=1e5)\n",
    "    # Uranium model for intercept\n",
    "    mu_a = gamma_0 + gamma_1*u\n",
    "    # County variation not explained by uranium\n",
    "    eps_a = Normal('eps_a', mu=0, sigma=sigma_a, shape=counties)\n",
    "    a = Deterministic('a', mu_a + eps_a[county])\n",
    "    \n",
    "    # Common slope\n",
    "    b = Normal('b', mu=0., sigma=1e5)\n",
    "    \n",
    "    # Model error\n",
    "    sigma_y = Uniform('sigma_y', lower=0, upper=100)\n",
    "    \n",
    "    # Expected value\n",
    "    y_hat = a + b * floor_measure\n",
    "    # Data likelihood\n",
    "    y_like = Normal('y_like', mu=y_hat, sigma=sigma_y, observed=log_radon)\n",
    "model_to_graphviz(hierarchical_intercept)\n",
    "\n",
    "with hierarchical_intercept:\n",
    "    hierarchical_intercept_trace = sample(1000,tune=1000)\n",
    "    \n",
    "import pymc3 as pm\n",
    "pm.traceplot(hierarchical_intercept_trace,legend=True)\n",
    "\n",
    "a_means = hierarchical_intercept_trace['a'].mean(axis=0)\n",
    "b_means = hierarchical_intercept_trace['b'].mean(axis=0)\n",
    "y_hat = a_means + b_means * floor_measure\n",
    "\n",
    "data=srrs_mn[['county','log_radon','log_radon_predict']].groupby('county').mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(25,8))\n",
    "plt.bar(data['county'],data['log_radon'])\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.title('Average_log_Randon_level_by_county')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(25,8))\n",
    "plt.bar(data['county'],data['log_radon_predict'],color='orange')\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.title('Predicted_Average_log_Randon_level_by_county')\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
